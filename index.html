<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <title>リアルタイム感情認識カメラ</title>
  <style>
    body { font-family: sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #2c3e50; }
    #video-container { position: relative; }
    #output_canvas { position: absolute; top: 0; left: 0; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
</head>

<body>
  <div id="video-container">
    <video id="input_video" width="720" height="560" autoplay muted></video>
    <canvas id="output_canvas" width="720" height="560"></canvas>
  </div>

  <script type="module">
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');

    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
      
      let emotion = "Neutral";

      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {color: '#C0C0C070', lineWidth: 1});

       // --- 最終調整版 感情判定ロジック ---

        // 判定の基準値（感度調整用）
        const SURPRISE_THRESHOLD = 0.4;   // 口の縦開き度合い
        const HAPPY_THRESHOLD = 0.06;     // 口角の上がり度合い
        const SAD_THRESHOLD = 0.025;      // 口角の下がり度合い
        const ANGRY_THRESHOLD = 0.17;     // 眉間の寄り具合

        // 安定した基準値として、両目の間の距離を計算
        const interEyeDistance = Math.hypot(landmarks[263].x - landmarks[33].x, landmarks[263].y - landmarks[33].y);

        // 各パーツの座標を取得
        const mouthLeft = landmarks[61], mouthRight = landmarks[291];
        const mouthTop = landmarks[13], mouthBottom = landmarks[14];
        const eyebrowLeftInner = landmarks[293], eyebrowRightInner = landmarks[63];
        const noseBottom = landmarks[2];
        
        // --- 各感情の条件を計算 ---

        // 驚き (Surprise): 口が大きく開いているか
        const mouthHeight = Math.hypot(mouthTop.x - mouthBottom.x, mouthTop.y - mouthBottom.y);
        const normalizedMouthHeight = mouthHeight / interEyeDistance;
        const isSurprised = normalizedMouthHeight > SURPRISE_THRESHOLD;
        
        // 幸せ (Happy): 口角が上がっているか
        const mouthCornerY = (mouthLeft.y + mouthRight.y) / 2;
        const smileIntensity = noseBottom.y - mouthCornerY;
        const normalizedSmileIntensity = smileIntensity / interEyeDistance;
        const isHappy = normalizedSmileIntensity > HAPPY_THRESHOLD;

        // 悲しみ (Sad): 口角が下がっているか
        const mouthCenterY = (mouthTop.y + mouthBottom.y) / 2;
        const mouthCornerDrop = mouthCornerY - mouthCenterY;
        const normalizedMouthCornerDrop = mouthCornerDrop / interEyeDistance;
        const isSad = normalizedMouthCornerDrop > SAD_THRESHOLD;

        // 怒り (Angry): 眉間が寄っているか
        const innerEyebrowDistance = Math.hypot(eyebrowLeftInner.x - eyebrowRightInner.x, eyebrowLeftInner.y - eyebrowRightInner.y);
        const normalizedInnerEyebrowDistance = innerEyebrowDistance / interEyeDistance;
        const isAngry = normalizedInnerEyebrowDistance < ANGRY_THRESHOLD;

        // --- 条件に基づいて最終的な感情を決定 ---
        if (isSurprised) {
            emotion = "Surprise";
        } else if (isHappy) {
            emotion = "Happy";
        } else if (isSad) {
            emotion = "Sad";
        } else if (isAngry) {
            emotion = "Angry";
        }
      }
      
      // 判定結果を描画
      canvasCtx.font = '60px Arial';
      canvasCtx.fillStyle = '#FF0000';
      canvasCtx.fillText(emotion, 20, 70);
      canvasCtx.restore();
    }

    const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
    faceMesh.onResults(onResults);

    const camera = new Camera(videoElement, {
      onFrame: async () => await faceMesh.send({image: videoElement}),
      width: 720,
      height: 560
    });
    camera.start();
  </script>
</body>
</html>
