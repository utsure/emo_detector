<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <title>リアルタイム感情認識カメラ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      background: #2c3e50;
      /* 縦に並べるように変更 */
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    #info-text {
      color: white;
      font-size: 24px;
      padding: 10px;
    }
    #video-container {
      position: relative;
      width: 90vw; /* 画面幅の90%を使う */
      max-width: 720px; /* PCでの最大幅 */
    }
    /* 映像とキャンバスをアスペクト比16:9に保つ */
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
    #video-container::before {
      content: '';
      display: block;
      padding-top: calc(560 / 720 * 100%); /* アスペクト比を維持 */
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
</head>

<body>
  <div id="info-text">カメラに顔を映してください</div>
  <div id="video-container">
    <video id="input_video" autoplay muted playsinline></video>
    <canvas id="output_canvas"></canvas>
  </div>

  <script>
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const infoText = document.getElementById('info-text');

    function onResults(results) {
      // キャンバスのサイズをビデオのサイズに合わせる
      canvasElement.width = videoElement.videoWidth;
      canvasElement.height = videoElement.videoHeight;

      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
      
      let emotion = "Neutral";

      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {color: '#C0C0C070', lineWidth: 1});

        // --- 感情判定ロジック ---
        const SURPRISE_THRESHOLD = 0.4;
        const HAPPY_THRESHOLD = 0.06;
        const SAD_THRESHOLD = 0.025;
        const ANGRY_THRESHOLD = 0.17;

        const interEyeDistance = Math.hypot(landmarks[263].x - landmarks[33].x, landmarks[263].y - landmarks[33].y);
        
        const mouthLeft = landmarks[61], mouthRight = landmarks[291];
        const mouthTop = landmarks[13], mouthBottom = landmarks[14];
        const eyebrowLeftInner = landmarks[293], eyebrowRightInner = landmarks[63];
        const noseBottom = landmarks[2];
        
        const mouthHeight = Math.hypot(mouthTop.x - mouthBottom.x, mouthTop.y - mouthBottom.y);
        const normalizedMouthHeight = mouthHeight / interEyeDistance;
        const isSurprised = normalizedMouthHeight > SURPRISE_THRESHOLD;
        
        const mouthCornerY = (mouthLeft.y + mouthRight.y) / 2;
        const smileIntensity = noseBottom.y - mouthCornerY;
        const normalizedSmileIntensity = smileIntensity / interEyeDistance;
        const isHappy = normalizedSmileIntensity > HAPPY_THRESHOLD;

        const mouthCenterY = (mouthTop.y + mouthBottom.y) / 2;
        const mouthCornerDrop = mouthCornerY - mouthCenterY;
        const normalizedMouthCornerDrop = mouthCornerDrop / interEyeDistance;
        const isSad = normalizedMouthCornerDrop > SAD_THRESHOLD;

        const innerEyebrowDistance = Math.hypot(eyebrowLeftInner.x - eyebrowRightInner.x, eyebrowLeftInner.y - eyebrowRightInner.y);
        const normalizedInnerEyebrowDistance = innerEyebrowDistance / interEyeDistance;
        const isAngry = normalizedInnerEyebrowDistance < ANGRY_THRESHOLD;

        if (isSurprised) { emotion = "Surprise"; } 
        else if (isHappy) { emotion = "Happy"; }
        else if (isSad) { emotion = "Sad"; }
        else if (isAngry) { emotion = "Angry"; }
      }
      
      // 判定結果を上のテキストに表示
      infoText.innerText = `Emotion: ${emotion}`;
      
      canvasCtx.restore();
    }

    const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
    faceMesh.onResults(onResults);

    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({image: videoElement});
      },
      // スマホではwidth/heightを直接指定しない方が安定する
    });
    camera.start();
  </script>
</body>
</html>
