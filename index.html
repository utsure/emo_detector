<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <title>リアルタイム感情認識カメラ</title>
  <style>
    body { font-family: sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #2c3e50; }
    #video-container { position: relative; }
    #output_canvas { position: absolute; top: 0; left: 0; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
</head>

<body>
  <div id="video-container">
    <video id="input_video" width="720" height="560" autoplay muted></video>
    <canvas id="output_canvas" width="720" height="560"></canvas>
  </div>

  <script type="module">
    const videoElement = document.getElementById('input_video');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');

    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
      
      let emotion = "Neutral";

      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        drawConnectors(canvasCtx, landmarks, FACEMESH_TESSELATION, {color: '#C0C0C070', lineWidth: 1});

        // --- ここから感情判定ロジック ---

        // 判定の基準値（感度調整用）
        const SAD_TILT_THRESHOLD = 1.0;       // この値が大きいほど「下を向いている」と判定
        const ANGRY_PUFF_THRESHOLD = 1.6;     // この値が小さいほど「頬が膨らんでいる」と判定
        const SURPRISE_OPEN_THRESHOLD = 0.35; // 口の縦開き度合い
        const SURPRISE_ASPECT_RATIO = 1.8;  // この値が小さいほど「口が丸い」と判定
        const HAPPY_WIDTH_THRESHOLD = 0.75;   // 口の横幅の広がり度合い
        const HAPPY_SMILE_THRESHOLD = 0.04;   // 口角の上がり度合い

        // 安定した基準値として、両目の間の距離を計算
        const interEyeDistance = Math.hypot(landmarks[263].x - landmarks[33].x, landmarks[263].y - landmarks[33].y);

        // --- 各感情の条件を計算 ---

        // 悲しみ (Sad): 下を向いているか
        const headTop = landmarks[10];
        const noseTip = landmarks[4];
        const headTiltDistance = noseTip.y - headTop.y;
        const normalizedHeadTilt = headTiltDistance / interEyeDistance;
        const isSad = normalizedHeadTilt > SAD_TILT_THRESHOLD;
        
        // 怒り (Angry): 頬が膨らんでいるか
        const cheekLeft = landmarks[50];
        const cheekRight = landmarks[280];
        const cheekWidth = Math.hypot(cheekLeft.x - cheekRight.x, cheekLeft.y - cheekRight.y);
        const normalizedCheekWidth = cheekWidth / interEyeDistance;
        const isAngry = normalizedCheekWidth > ANGRY_PUFF_THRESHOLD;

        // 驚き (Surprise): 口が縦に大きく、かつ丸く開いているか
        const mouthTop = landmarks[13], mouthBottom = landmarks[14];
        const mouthLeft = landmarks[61], mouthRight = landmarks[291];
        const mouthHeight = Math.hypot(mouthTop.x - mouthBottom.x, mouthTop.y - mouthBottom.y);
        const mouthWidth = Math.hypot(mouthLeft.x - mouthRight.x, mouthLeft.y - mouthRight.y);
        const normalizedMouthHeight = mouthHeight / interEyeDistance;
        const mouthAspectRatio = mouthWidth / mouthHeight;
        const isSurprised = normalizedMouthHeight > SURPRISE_OPEN_THRESHOLD && mouthAspectRatio < SURPRISE_ASPECT_RATIO;
        
        // 幸せ (Happy): 口角が上がり、口が横に広いか
        const noseBottom = landmarks[2];
        const mouthCornerY = (mouthLeft.y + mouthRight.y) / 2;
        const smileIntensity = noseBottom.y - mouthCornerY;
        const normalizedSmileIntensity = smileIntensity / interEyeDistance;
        const normalizedMouthWidth = mouthWidth / interEyeDistance;
        const isHappy = normalizedMouthWidth > HAPPY_WIDTH_THRESHOLD && normalizedSmileIntensity > HAPPY_SMILE_THRESHOLD;

        // --- 条件に基づいて最終的な感情を決定 (判定の優先順位が重要) ---
        if (isSad) {
            emotion = "Sad";
        } else if (isSurprised) {
            emotion = "Surprise";
        } else if (isHappy) {
            emotion = "Happy";
        } else if (isAngry) {
            emotion = "Angry";
        }
        // 上記のいずれでもなければ "Neutral" のまま
      }
      
      // 判定結果を描画
      canvasCtx.font = '60px Arial';
      canvasCtx.fillStyle = '#FF0000';
      canvasCtx.fillText(emotion, 20, 70);
      canvasCtx.restore();
    }

    const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
    faceMesh.onResults(onResults);

    const camera = new Camera(videoElement, {
      onFrame: async () => await faceMesh.send({image: videoElement}),
      width: 720,
      height: 560
    });
    camera.start();
  </script>
</body>
</html>
